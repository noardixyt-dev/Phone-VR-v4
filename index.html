<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover" />
<title>Stereo VR / AR Viewer — Niantic 6DOF + Hand pinch</title>
<style>
  :root{--ui-bg:rgba(0,0,0,0.45);--outline:rgba(255,255,255,0.06)}
  html,body{margin:0;padding:0;height:100%;width:100%;background:#000;color:#fff;font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial;overflow:hidden}
  /* UI top */
  #controls{position:fixed;z-index:220;top:10px;left:12px;display:flex;gap:10px;align-items:center;transition:opacity .32s ease,transform .32s ease;pointer-events:auto}
  #controls.hidden{opacity:0;pointer-events:none;transform:translateY(-8px)}
  .control{background:var(--ui-bg);backdrop-filter:blur(6px);padding:8px;border-radius:8px;font-size:13px;color:#fff}
  #fovSlider{width:220px}
  #fullscreenBtn{position:fixed;top:10px;right:10px;z-index:220;padding:8px 12px;border-radius:8px;background:rgba(255,255,255,0.06);border:1px solid rgba(255,255,255,0.06);color:#fff;font-size:14px;transition:opacity .32s;pointer-events:auto}
  #startBtn{position:fixed;top:50%;left:50%;transform:translate(-50%,-50%);padding:14px 20px;border-radius:10px;background:#111;color:#fff;z-index:320;border:1px solid rgba(255,255,255,0.06);font-size:16px;cursor:pointer}
  #hint{position:fixed;left:50%;bottom:10px;transform:translateX(-50%);font-size:12px;opacity:0.95;padding:6px 10px;border-radius:8px;background:rgba(0,0,0,0.35);z-index:210}
  #portraitOverlay{position:fixed;inset:0;display:none;align-items:center;justify-content:center;background:rgba(0,0,0,0.92);z-index:9999;color:#fff;font-size:20px;padding:20px;text-align:center;pointer-events:auto}
  /* stereo container: bottom-anchored, windows grow upwards */
  #stereoWrap{position:fixed;inset:0;display:flex;justify-content:center;align-items:flex-end;gap:var(--gap,12px);padding-bottom:12px;pointer-events:none;z-index:10}
  .eyeWin{width:var(--eye-w,360px);height:var(--eye-h,240px);border-radius:14px;overflow:hidden;border:2px solid var(--outline);box-shadow:0 6px 22px rgba(0,0,0,0.6);background:#000;position:relative}
  .eyeVideo{position:absolute;inset:0;width:100%;height:100%;object-fit:cover;transform-origin:center center}
  /* overlay canvas for 3D menu (three.js) */
  canvas#overlay{position:fixed;left:0;top:0;width:100%;height:100%;z-index:40;pointer-events:none;display:block}
  /* outlines & debugging */
  .eye-outline{position:absolute;pointer-events:none;z-index:200;border-radius:12px;box-shadow:0 6px 22px rgba(0,0,0,0.6);border:2px solid var(--outline)}
  #debugLog{position:fixed;left:10px;bottom:10px;color:#0f0;background:rgba(0,0,0,0.6);padding:6px;border-radius:6px;font-size:11px;z-index:9998;display:none}
  /* minimal crosshair (none by default) */
  .cross{position:absolute;left:50%;top:50%;transform:translate(-50%,-50%);z-index:300;pointer-events:none;font-size:14px}
</style>
<!--
  IMPORTANT: To enable Niantic Lightship WebAR 6DOF, add the official Niantic JS file before this file runs.
  Example placeholder (replace with exact Niantic CDN or local copy):
  <script src="https://unpkg.com/@nianticlabs/volumetric@latest/dist/niantic-volumetric.min.js"></script>

  To enable MediaPipe Hands hand tracking, include the MediaPipe hands script and the wasm/data files:
  Example:
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  And host the wasm/data files next to it or use the official CDN (MediaPipe requires .wasm & .data assets).
-->
</head>
<body>
  <div id="controls" class="hidden" style="display:none">
    <div class="control">
      <div style="font-size:12px;margin-bottom:6px">FOV (eye window) <span id="fovVal">70%</span></div>
      <input id="fovSlider" type="range" min="40" max="100" value="70" />
    </div>
  </div>

  <button id="fullscreenBtn" style="display:none">Fullscreen</button>
  <button id="startBtn">Start VR (camera & motion)</button>
  <div id="hint">Double-tap to toggle anchored menu • Tap top to show UI</div>

  <div id="portraitOverlay">Please rotate your device to landscape and grant camera & motion permission</div>

  <div id="stereoWrap" aria-hidden="true">
    <div id="leftWin" class="eyeWin"><video id="videoLeft" class="eyeVideo" playsinline autoplay muted></video></div>
    <div id="rightWin" class="eyeWin"><video id="videoRight" class="eyeVideo" playsinline autoplay muted></video></div>
  </div>

  <canvas id="overlay"></canvas>
  <div id="debugLog"></div>

  <!-- Three.js (ES5 UMD build) -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.min.js"></script>

  <!-- Optional: Niantic Lightship WebAR script: add the real one in your hosted repo or a CDN -->
  <!-- <script src="URL_TO_NIANTIC_WEBAR_JS"></script> -->

  <!-- Optional: MediaPipe Hands: add in your repo or CDN if you want hand-tracking -->
  <!-- <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script> -->

<script>
/* =========================
   Stereo Viewer + Niantic 6DOF + hand-tracking integration
   Single-file implementation. Paste into index.html, host over HTTPS.

   Notes:
   - If Niantic WebAR script is present as window.Niantic... the code will attempt to use it for 6DOF SLAM.
   - If MediaPipe Hands is present as global `Hands` the code will use it for palm+pinch detection.
   - If those libs are missing, the code falls back to deviceorientation for menu placement and touch drag for menu movement.

   This file:
   - starts rear camera at top available resolution & frameRate hints
   - attaches same stream to both video elements (left/right)
   - creates Three.js overlay canvas and a single scene for the menu (renders to both eyes using scissor)
   - double-tap toggles menu spawn/hide
   - top tap reveals UI controls; they auto-hide after 10s
   - pinch-to-drag via hand-tracking or touch drag fallback
   ========================= */

const startBtn = document.getElementById('startBtn');
const controls = document.getElementById('controls');
const fullscreenBtn = document.getElementById('fullscreenBtn');
const fovSlider = document.getElementById('fovSlider');
const fovVal = document.getElementById('fovVal');
const portraitOverlay = document.getElementById('portraitOverlay');
const leftWin = document.getElementById('leftWin');
const rightWin = document.getElementById('rightWin');
const videoLeft = document.getElementById('videoLeft');
const videoRight = document.getElementById('videoRight');
const overlay = document.getElementById('overlay');
const debugLog = document.getElementById('debugLog');

let uiHideTimer = null;
const UI_HIDE_MS = 10000;
function showUI(){ controls.style.display='flex'; controls.classList.remove('hidden'); fullscreenBtn.style.display='block'; resetUIHideTimer(); }
function hideUI(){ controls.classList.add('hidden'); fullscreenBtn.style.display='none'; }
function resetUIHideTimer(){ if(uiHideTimer) clearTimeout(uiHideTimer); uiHideTimer = setTimeout(()=>{ hideUI(); }, UI_HIDE_MS); }
window.addEventListener('pointermove', ()=> resetUIHideTimer(), { passive:true });
controls.addEventListener('pointerdown', ()=> showUI());

/* state */
let stream = null;
let videoTextureLeft = null, videoTextureRight = null; // not used directly - we use <video> elements for passthrough
let eyeScalePct = parseFloat(fovSlider.value);
fovVal.textContent = Math.round(eyeScalePct) + '%';

/* Orientation helpers (landscape-calibrated, no roll) */
const zee = new THREE.Vector3(0,0,1);
const qPortraitToThree = new THREE.Quaternion(-Math.sqrt(0.5),0,0,Math.sqrt(0.5));
let deviceQuat = new THREE.Quaternion();
let deviceOrientationEnabled = false;
function getScreenOrientationDeg(){ if (screen && screen.orientation && typeof screen.orientation.angle === 'number') return screen.orientation.angle; return window.orientation || 0; }
function setObjectQuaternionFromSensor(quatOut, alpha, beta, gamma){
  const orient = getScreenOrientationDeg(); const deg = Math.PI/180;
  const e = new THREE.Euler((beta||0)*deg, (alpha||0)*deg, -(gamma||0)*deg, 'YXZ');
  quatOut.setFromEuler(e);
  let baseRot = new THREE.Quaternion();
  if (orient === 90) baseRot.setFromAxisAngle(zee, -Math.PI/2);
  else if (orient === -90 || orient === 270) baseRot.setFromAxisAngle(zee, Math.PI/2);
  else if (orient === 180) baseRot.setFromAxisAngle(zee, Math.PI);
  quatOut.multiply(qPortraitToThree);
  quatOut.multiply(baseRot);
  const ex = new THREE.Euler().setFromQuaternion(quatOut,'YXZ'); ex.z = 0; quatOut.setFromEuler(ex);
}
async function enableDeviceOrientation(){
  if (typeof DeviceOrientationEvent !== 'undefined' && typeof DeviceOrientationEvent.requestPermission === 'function'){
    try {
      const perm = await DeviceOrientationEvent.requestPermission();
      if (perm === 'granted') window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true);
      else window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true);
    } catch(e){ window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true); }
  } else window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true);
}

/* Choose rear camera heuristics and request highest-res/fps available */
async function enumerateVideoInputs(){ try{ const devs = await navigator.mediaDevices.enumerateDevices(); return devs.filter(d=>d.kind==='videoinput'); }catch(e){ return []; } }
async function chooseRearDeviceId(){
  try{
    const cams = await enumerateVideoInputs();
    for(const c of cams){
      const L=(c.label||'').toLowerCase();
      if(L.includes('back')||L.includes('rear')||L.includes('environment')||L.includes('main')||L.includes('wide')) return c.deviceId;
    }
    for(const c of cams){
      const L=(c.label||'').toLowerCase();
      if(!L.includes('front') && !L.includes('selfie')) return c.deviceId;
    }
    return cams.length?cams[0].deviceId:null;
  }catch(e){ return null; }
}

async function startCameraStream(){
  const deviceId = await chooseRearDeviceId();
  const tryRes = [{w:3840,h:2160},{w:1920,h:1080},{w:1280,h:720}];
  const fps = [60,30];
  for(const r of tryRes){
    for(const f of fps){
      try{
        const constraints = deviceId ? { video:{ deviceId:{ exact:deviceId }, width:{ ideal: r.w }, height:{ ideal: r.h }, frameRate:{ ideal: f } }, audio:false }
                                     : { video:{ facingMode:{ ideal:'environment' }, width:{ ideal: r.w }, height:{ ideal: r.h }, frameRate:{ ideal: f } }, audio:false };
        const s = await navigator.mediaDevices.getUserMedia(constraints);
        return s;
      }catch(e){ /* try next */ }
    }
  }
  // worst-case fallback
  return navigator.mediaDevices.getUserMedia({ video:true, audio:false });
}

/* layout eyes bottom anchored (grow upward) */
function layoutEyes(){
  const scale = Math.max(0.3, Math.min(1.0, eyeScalePct/100));
  let eyeH = Math.round(window.innerHeight * scale);
  let eyeW = Math.floor(eyeH * 1.5);
  let gap = Math.max(8, Math.round(eyeW * 0.06));
  if (eyeW * 2 + gap > window.innerWidth){
    const avail = window.innerWidth - gap;
    eyeW = Math.floor(avail / 2);
    eyeH = Math.floor(eyeW * 2/3);
  }
  document.documentElement.style.setProperty('--eye-w', eyeW + 'px');
  document.documentElement.style.setProperty('--eye-h', eyeH + 'px');
  document.documentElement.style.setProperty('--gap', gap + 'px');
}

/* portrait overlay */
function updatePortrait(){
  if (window.innerHeight > window.innerWidth){
    portraitOverlay.style.display = 'flex';
    controls.classList.add('hidden');
    fullscreenBtn.style.display='none';
  } else {
    portraitOverlay.style.display = 'none';
    if (!controls.classList.contains('hidden')) controls.style.display='flex';
    if (controls.style.display !== 'none') fullscreenBtn.style.display='block';
  }
}

/* ===================== Three.js overlay & Menu ===================== */

let renderer, scene3D, perspectiveBase, camLeft, camRight;
let menuMesh = null, menuBar = null;
const FIXED_IPD = 0.064;
let menuVisible = false;

function initThreeOverlay(){
  renderer = new THREE.WebGLRenderer({ canvas: overlay, antialias:true, alpha:true });
  renderer.setPixelRatio(window.devicePixelRatio || 1);
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.autoClear = false;

  scene3D = new THREE.Scene();
  scene3D.add(new THREE.AmbientLight(0xffffff,0.9));
  const dl = new THREE.DirectionalLight(0xffffff,0.2); dl.position.set(1,2,2); scene3D.add(dl);

  perspectiveBase = new THREE.PerspectiveCamera(70, window.innerWidth/window.innerHeight, 0.01, 1000);
  camLeft = perspectiveBase.clone();
  camRight = perspectiveBase.clone();

  // menu (rounded rectangular look)
  const boxG = new THREE.BoxGeometry(0.9, 0.56, 0.03); // larger by default (16:9-ish)
  const boxM = new THREE.MeshStandardMaterial({ color:0x0f6feb, roughness:0.6, metalness:0.01, transparent:true, opacity:0.95, emissive:0x001830 });
  menuMesh = new THREE.Mesh(boxG, boxM);
  menuMesh.visible = false;
  scene3D.add(menuMesh);

  // pill bar at bottom
  const barG = new THREE.BoxGeometry(0.36, 0.04, 0.002);
  const barM = new THREE.MeshStandardMaterial({ color:0xffffff, transparent:true, opacity:0.9 });
  menuBar = new THREE.Mesh(barG, barM);
  menuBar.position.set(0, - (0.56/2 + 0.04/2 + 0.01), 0.017);
  menuMesh.add(menuBar);

  // initial layout
  layoutEyes();
  updatePortrait();

  // pointer & drag events (touch fallback)
  window.addEventListener('pointerdown', overlayPointerDown, { passive:true });
  window.addEventListener('pointermove', overlayPointerMove, { passive:true });
  window.addEventListener('pointerup', overlayPointerUp, { passive:true });

  window.addEventListener('resize', ()=>{ renderer.setSize(window.innerWidth, window.innerHeight); perspectiveBase.aspect = window.innerWidth/window.innerHeight; perspectiveBase.updateProjectionMatrix(); layoutEyes(); updatePortrait(); });

  requestAnimationFrame(animate);
}

/* spawn/hide menu - uses deviceQuat if Niantic not present, otherwise Niantic world pose */
function spawnMenuAtForward(distance=1.4){
  // spawn position relative to origin/camera: forward vector in world
  const forward = new THREE.Vector3(0,0,-1);
  // if Niantic SLAM provided a world->camera transform you'd use that; here we use deviceQuat for orientation
  if (deviceOrientationEnabled) forward.applyQuaternion(deviceQuat);
  const spawnPos = forward.clone().multiplyScalar(distance);
  menuMesh.position.copy(spawnPos);
  // face horizontally toward camera
  const toCam = new THREE.Vector3().subVectors(new THREE.Vector3(0,0,0), menuMesh.position);
  toCam.y = 0;
  menuMesh.lookAt(menuMesh.position.clone().add(toCam));
  menuMesh.up.set(0,1,0);
  // scale according to eyeScalePct (70% default)
  const baseScale = Math.max(0.6, eyeScalePct/70);
  menuMesh.scale.setScalar(baseScale);
  menuMesh.visible = true;
  menuVisible = true;
  popScale(menuMesh, baseScale, 200);
}
function hideMenu(){
  shrinkHide(menuMesh, 150);
  menuVisible = false;
}

/* small pop tween helpers */
function popScale(obj, target=1, dur=220){
  const start = performance.now();
  const sx = obj.scale.x;
  function step(now){
    const t = Math.min(1, (now - start)/dur);
    const e = 1 - Math.pow(1-t, 3);
    const v = sx + (target - sx) * e;
    obj.scale.set(v,v,v);
    if (t < 1) requestAnimationFrame(step);
  }
  requestAnimationFrame(step);
}
function shrinkHide(obj, dur=160){
  const start = performance.now();
  const sx = obj.scale.x;
  function step(now){
    const t = Math.min(1, (now - start)/dur);
    const e = Math.pow(1 - t, 2);
    obj.scale.set(sx * e, sx * e, sx * e);
    if (t < 1) requestAnimationFrame(step);
    else { obj.visible = false; obj.scale.set(sx, sx, sx); }
  }
  requestAnimationFrame(step);
}

/* drag input handling (touch fallback) */
let dragging=false, dragStart=null, dragCam=null;
const raycaster = new THREE.Raycaster();
function screenToNDC(x,y){ return new THREE.Vector2((x/window.innerWidth)*2 - 1, - (y/window.innerHeight)*2 + 1); }
function overlayPointerDown(e){
  const now = Date.now();
  if (now - lastTap < 300){ toggleMenu(); } // double-tap also handled here
  lastTap = now;

  if (!menuMesh.visible) return;
  const ndc = screenToNDC(e.clientX, e.clientY);
  raycaster.setFromCamera(ndc, camLeft);
  const hits = raycaster.intersectObject(menuBar, true);
  if (hits.length > 0){
    dragging = true;
    dragStart = { x: e.clientX, y: e.clientY, startPos: menuMesh.position.clone() };
    dragCam = perspectiveBase;
  }
}
function overlayPointerMove(e){
  if (!dragging || !dragStart) return;
  const ndcNow = screenToNDC(e.clientX, e.clientY);
  const ndcThen = screenToNDC(dragStart.x, dragStart.y);
  const delta = ndcNow.clone().sub(ndcThen);
  const cam = dragCam;
  const distance = menuMesh.position.length() || 1.4;
  const vFov = cam.fov * Math.PI/180;
  const worldH = 2 * Math.tan(vFov/2) * distance;
  const worldW = worldH * cam.aspect;
  const worldDelta = new THREE.Vector3(-delta.x * worldW/2, -delta.y * worldH/2, 0);
  worldDelta.applyQuaternion(cam.quaternion);
  menuMesh.position.copy(dragStart.startPos.clone().add(worldDelta));
}
function overlayPointerUp(e){ dragging=false; dragStart=null; }

/* hover visual pulse for menu bar */
function hoverPulse(){
  if (!menuMesh || !menuMesh.visible) return;
  const ndc = new THREE.Vector2(0,0);
  raycaster.setFromCamera(ndc, camLeft);
  const hits = raycaster.intersectObject(menuBar, true);
  if (hits.length > 0){
    menuBar.material.opacity = 1.0;
    menuBar.material.emissive = new THREE.Color(0xaaaaaa);
  } else {
    menuBar.material.opacity = 0.9;
    menuBar.material.emissive = new THREE.Color(0x000000);
  }
}

/* render loop: render same 3D scene twice (left/right) to match each eye window area */
function animate(){
  requestAnimationFrame(animate);
  if (!renderer) return;
  if (deviceOrientationEnabled) perspectiveBase.quaternion.copy(deviceQuat);
  else perspectiveBase.quaternion.identity();

  // left and right DOM rects
  const leftRect = leftWin.getBoundingClientRect();
  const rightRect = rightWin.getBoundingClientRect();
  const leftViewportY = window.innerHeight - leftRect.top - leftRect.height;

  renderer.setScissorTest(true);
  // left
  renderer.setScissor(leftRect.left, leftViewportY, leftRect.width, leftRect.height);
  renderer.setViewport(leftRect.left, leftViewportY, leftRect.width, leftRect.height);
  renderer.clear();
  camLeft.position.set(-FIXED_IPD/2, 0, 0);
  camLeft.quaternion.copy(perspectiveBase.quaternion);
  camLeft.updateMatrixWorld();
  renderer.clearDepth();
  renderer.render(scene3D, camLeft);

  // right
  const rightViewportY = window.innerHeight - rightRect.top - rightRect.height;
  renderer.setScissor(rightRect.left, rightViewportY, rightRect.width, rightRect.height);
  renderer.setViewport(rightRect.left, rightViewportY, rightRect.width, rightRect.height);
  renderer.clear();
  camRight.position.set(FIXED_IPD/2, 0, 0);
  camRight.quaternion.copy(perspectiveBase.quaternion);
  camRight.updateMatrixWorld();
  renderer.clearDepth();
  renderer.render(scene3D, camRight);

  renderer.setScissorTest(false);

  hoverPulse();
}

/* double-tap toggle (reliable) */
let lastTap = 0;
function toggleMenu(){ if (!menuMesh) return; if (!menuMesh.visible) spawnMenuAtForward(1.4); else hideMenu(); }

/* ===================== Hand tracking (MediaPipe) integration ===================== */

let handsAPI = null; // will hold MediaPipe Hands instance if available
let handActive = false;
let palmDot = { visible:false, pos:new THREE.Vector3(), pinch:false }; // palm point in world coords
let handSmoothing = { alpha:0.85, prev: null };

async function initHandTrackingIfAvailable(videoElement){
  // Attempt to detect MediaPipe Hands global (if user included the script)
  if (typeof Hands !== 'undefined'){
    try{
      handsAPI = new Hands({locateFile: (file) => {
        // If you host files in your repo, return the correct path here (wasm, .bin etc).
        // Default assumption: user put the mediapipe hands files in the same folder.
        return file;
      }});
      handsAPI.setOptions({ maxNumHands:1, minDetectionConfidence:0.6, minTrackingConfidence:0.6 });
      handsAPI.onResults(onHandsResults);
      // create a hidden canvas to feed frames (we use video element with requestVideoFrameCallback)
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      function processFrame(){
        if (!videoElement || videoElement.readyState < 2) { requestAnimationFrame(processFrame); return; }
        canvas.width = videoElement.videoWidth; canvas.height = videoElement.videoHeight;
        ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
        handsAPI.send({image: canvas}).catch(()=>{});
        requestAnimationFrame(processFrame);
      }
      requestAnimationFrame(processFrame);
      console.log('MediaPipe Hands initialized');
      return true;
    }catch(e){
      console.warn('MediaPipe Hands init failed', e);
      handsAPI = null;
      return false;
    }
  } else {
    console.info('MediaPipe Hands not present; hand tracking disabled (falls back to touch drag)');
    return false;
  }
}

function onHandsResults(results){
  // results.multiHandLandmarks is an array
  if (!results || !results.multiHandLandmarks || results.multiHandLandmarks.length === 0){
    handActive = false; palmDot.visible = false; return;
  }
  const landmarks = results.multiHandLandmarks[0]; // array of 21 landmarks
  // palm center approx: average of wrist and middle finger base
  const wrist = landmarks[0];
  const mcp = landmarks[9]; // middle finger MCP
  const palmX = (wrist.x + mcp.x) / 2;
  const palmY = (wrist.y + mcp.y) / 2;
  // normalized palm coords [0..1] relative to video
  // convert to NDC: x: [0..1] -> [-1..1], y:[0..1] -> [1..-1]
  const ndc = new THREE.Vector2((palmX*2)-1, -((palmY*2)-1));
  // map ndc to a world point at a projected distance in front of camera (e.g. 1.4m)
  const distance = 1.4;
  const vFov = perspectiveBase.fov * Math.PI/180;
  const worldH = 2 * Math.tan(vFov/2) * distance;
  const worldW = worldH * perspectiveBase.aspect;
  const worldX = (ndc.x) * (worldW/2);
  const worldY = (ndc.y) * (worldH/2);
  const worldPoint = new THREE.Vector3(worldX, worldY, -distance);
  worldPoint.applyQuaternion(perspectiveBase.quaternion);
  // smoothing
  if (!handSmoothing.prev) handSmoothing.prev = worldPoint.clone();
  handSmoothing.prev.lerp(worldPoint, 1 - handSmoothing.alpha);
  palmDot.pos.copy(handSmoothing.prev);
  palmDot.visible = true;
  // pinch detection: distance between thumb tip (4) and index tip (8)
  const thumb = landmarks[4], index = landmarks[8];
  const dx = thumb.x - index.x, dy = thumb.y - index.y, dz = (thumb.z||0) - (index.z||0);
  const screenDist = Math.sqrt(dx*dx + dy*dy + dz*dz);
  // empirical threshold; you may tweak
  palmDot.pinch = screenDist < 0.045;
  handActive = true;
  // If pinch and over menuBar, start dragging
  if (palmDot.pinch && menuMesh && menuMesh.visible){
    // project palmDot into camera NDC and then raycast into scene to intersect menu plane
    const camera = perspectiveBase;
    const pWorld = palmDot.pos.clone(); // world pos
    // convert world pos into screen NDC for raycaster origin:
    const toScreen = pWorld.clone().project(camera);
    const ndcx = toScreen.x, ndcy = toScreen.y;
    // ray from camera to world point
    raycaster.setFromCamera(new THREE.Vector2(ndcx, ndcy), camera);
    const hits = raycaster.intersectObject(menuMesh, true);
    if (hits.length > 0){
      // move menu to the hit point with small lag
      const hit = hits[0].point;
      menuMesh.position.lerp(hit.multiplyScalar(1.0), 0.35);
    }
  }
}

/* ===================== Start flow ===================== */

startBtn.addEventListener('click', async ()=>{
  startBtn.style.display = 'none';
  await enableDeviceOrientation();
  showUI();
  try{
    stream = await startCameraStream();
    // attach same stream to both videos
    videoLeft.srcObject = stream;
    videoRight.srcObject = stream;
    // start video playback
    try{ await videoLeft.play(); }catch(e){ console.warn('videoLeft play blocked', e); }
    try{ await videoRight.play(); }catch(e){ console.warn('videoRight play blocked', e); }
    // make overlay and three scene
    initThreeOverlay();
    // attempt to init hand tracking if MediaPipe present
    initHandTrackingIfAvailable(videoLeft).then(ok=>{
      if (!ok) debugLog.textContent = 'MediaPipe Hands not available — touch fallback enabled';
      debugLog.style.display = 'block';
      setTimeout(()=> debugLog.style.display='none', 3000);
    });
    // If Niantic Lightship API is present, try to init SLAM/anchors
    if (typeof window.Niantic !== 'undefined' || typeof window.NianticWeb !== 'undefined'){
      tryInitNiantic();
    } else {
      console.info('Niantic WebAR missing — falling back to device-orientation world spawn (3DOF-like). Add Niantic script for true 6DOF.');
    }
    // controls shown
    controls.style.display='flex';
    fullscreenBtn.style.display='block';
    // layout
    layoutEyes(); updatePortrait();
  }catch(err){
    console.error('Camera start failed', err);
    alert('Camera access failed: ' + (err && err.message ? err.message : err));
    startBtn.style.display = 'block';
  }
});

/* fullscreen */
fullscreenBtn.addEventListener('click', ()=>{
  if (!document.fullscreenElement) document.documentElement.requestFullscreen();
  else document.exitFullscreen();
  resetUIHideTimer();
});

/* FOV slider */
fovSlider.addEventListener('input', ()=> {
  eyeScalePct = parseFloat(fovSlider.value);
  fovVal.textContent = Math.round(eyeScalePct) + '%';
  layoutEyes();
  // scale menu with window size
  if (menuMesh && menuMesh.visible){
    menuMesh.scale.setScalar(Math.max(0.6, eyeScalePct / 70));
  }
  resetUIHideTimer();
});

/* top tap reveals UI */
window.addEventListener('pointerdown', (ev)=>{ if (ev.clientY <= 140) showUI(); });

/* resize/pause handling */
window.addEventListener('resize', ()=>{ layoutEyes(); updatePortrait(); if (renderer) { renderer.setSize(window.innerWidth, window.innerHeight); perspectiveBase.aspect = window.innerWidth/window.innerHeight; perspectiveBase.updateProjectionMatrix(); } });

/* Niantic WebAR integration attempt (best-effort) */
async function tryInitNiantic(){
  // This is a best-effort initializer — exact Niantic API may differ depending on version.
  // If you include the official Niantic WebAR script in your page, replace the code below with the library's init call.
  try{
    if (typeof window.Niantic !== 'undefined' && typeof window.Niantic.makeExperience === 'function'){
      console.log('Niantic global found — attempting to init Lightship experience');
      // Example pseudo-init: (replace with Niantic SDK-specific calls from docs)
      const experience = await window.Niantic.makeExperience({ container: document.body, videoStream: stream });
      // set up a callback to read world pose and update perspectiveBase/quaternion
      experience.on('pose', (pose)=>{ // pseudo
        // pose.orientation = [x,y,z,w] quaternion world->camera
        if (pose && pose.orientation){
          const q = new THREE.Quaternion(pose.orientation[0], pose.orientation[1], pose.orientation[2], pose.orientation[3]);
          // The exact mapping depends on SDK - you may need to convert coords.
          perspectiveBase.quaternion.copy(q);
        }
      });
      // for anchors you'd use experience.createAnchor(...) per SDK
      debugLog.style.display='block';
      debugLog.textContent = 'Niantic WebAR initialized (pseudo) — replace with real init per SDK';
      setTimeout(()=> debugLog.style.display='none', 3000);
      return true;
    } else {
      console.info('Niantic global not found or incompatible API; skipping Niantic init.');
      return false;
    }
  }catch(e){
    console.warn('Niantic init failed', e);
    return false;
  }
}

/* initial layout */
layoutEyes();
updatePortrait();

</script>
</body>
</html>
