<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover" />
<title>Stereo VR Viewer — Pinch-to-drag menu + stabilized hands</title>
<style>
  :root{
    --ui-bg: rgba(0,0,0,0.45);
    --outline: rgba(255,255,255,0.06);
  }
  html,body{margin:0;padding:0;height:100%;width:100%;background:#000;color:#fff;font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial;overflow:hidden}
  /* Eye windows container - bottom anchored so windows grow upward */
  #stereoWrap{
    position:fixed;inset:0;display:flex;justify-content:center;align-items:flex-end;gap:var(--gap,12px);padding-bottom:12px;pointer-events:none;z-index:2;
  }
  .eyeWin{
    width:var(--eye-w,360px); height:var(--eye-h,240px);
    border-radius:14px; overflow:hidden; border:2px solid var(--outline);
    box-shadow:0 6px 22px rgba(0,0,0,0.6); background:#000; position:relative;
  }
  .eyeVideo{ position:absolute; inset:0; width:100%; height:100%; object-fit:cover; transform-origin:center center; }
  /* overlay canvas for menu + pointer */
  canvas#overlay{ position:fixed; left:0; top:0; width:100%; height:100%; z-index:40; pointer-events:none; display:block; }
  /* UI */
  #controls{ position:fixed; left:12px; top:10px; z-index:60; display:flex; gap:10px; align-items:center; pointer-events:auto; transition:opacity .32s, transform .32s }
  #controls.hidden{ opacity:0; pointer-events:none; transform:translateY(-8px) }
  .control{ background:var(--ui-bg); backdrop-filter:blur(6px); padding:8px; border-radius:8px; font-size:13px; color:#fff }
  #fovSlider{ width:220px }
  #fullscreenBtn{ position:fixed; top:10px; right:10px; z-index:60; padding:8px 12px; border-radius:8px; background:rgba(255,255,255,0.06); border:1px solid rgba(255,255,255,0.06); color:#fff; font-size:14px; pointer-events:auto }
  #startBtn{ position:fixed; left:50%; top:50%; transform:translate(-50%,-50%); z-index:80; padding:14px 18px; border-radius:10px; background:#111; color:#fff; border:1px solid rgba(255,255,255,0.06); cursor:pointer }
  #hint{ position:fixed; left:50%; bottom:10px; transform:translateX(-50%); font-size:12px; background:rgba(0,0,0,0.35); padding:6px 10px; border-radius:8px; z-index:60 }
  #portraitOverlay{ position:fixed; inset:0; display:none; align-items:center; justify-content:center; background:rgba(0,0,0,0.92); z-index:9999; color:#fff; font-size:20px; padding:20px; text-align:center; pointer-events:auto }
  /* pointer dot style (for CSS fallbacks) */
  .dot{ width:10px;height:10px;border-radius:50%;background:#fff;position:absolute;z-index:100;pointer-events:none;box-shadow:0 0 8px rgba(255,255,255,0.8) }
  /* small helper */
  #log{position:fixed;left:12px;bottom:12px;background:rgba(0,0,0,0.6);color:#0f0;padding:6px;border-radius:6px;font-size:11px;z-index:9999;display:none}
</style>
</head>
<body>
  <button id="startBtn">Start VR (camera + motion)</button>

  <div id="controls" class="hidden" style="display:none">
    <div class="control">
      <div style="font-size:12px;margin-bottom:6px">FOV (eye window) <span id="fovVal">70%</span></div>
      <input id="fovSlider" type="range" min="40" max="100" value="70" />
    </div>
  </div>

  <button id="fullscreenBtn" style="display:none">Fullscreen</button>
  <div id="hint">Double-tap to toggle anchored menu • Tap top to show UI</div>
  <div id="portraitOverlay">Please rotate your device to landscape</div>
  <div id="log"></div>

  <div id="stereoWrap" aria-hidden="true">
    <div id="leftWin" class="eyeWin"><video id="videoLeft" class="eyeVideo" playsinline autoplay muted></video></div>
    <div id="rightWin" class="eyeWin"><video id="videoRight" class="eyeVideo" playsinline autoplay muted></video></div>
  </div>

  <canvas id="overlay"></canvas>

  <!-- Three.js -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.min.js"></script>

  <!-- MediaPipe Hands (cdn) - if unavailable, page will continue w/o pinch -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.4/camera_utils.js"></script>

<script>
(async function(){
  // ---- Elements / state ----
  const startBtn = document.getElementById('startBtn');
  const controls = document.getElementById('controls');
  const fullscreenBtn = document.getElementById('fullscreenBtn');
  const fovSlider = document.getElementById('fovSlider');
  const fovVal = document.getElementById('fovVal');
  const portraitOverlay = document.getElementById('portraitOverlay');
  const leftWin = document.getElementById('leftWin');
  const rightWin = document.getElementById('rightWin');
  const videoLeft = document.getElementById('videoLeft');
  const videoRight = document.getElementById('videoRight');
  const overlay = document.getElementById('overlay');
  const hint = document.getElementById('hint');
  const logEl = document.getElementById('log');

  let uiHideTimer = null;
  const UI_HIDE_MS = 10000;
  function showUI(){ controls.style.display='flex'; controls.classList.remove('hidden'); fullscreenBtn.style.display='block'; resetUIHideTimer(); }
  function hideUI(){ controls.classList.add('hidden'); fullscreenBtn.style.display='none'; }
  function resetUIHideTimer(){ if (uiHideTimer) clearTimeout(uiHideTimer); uiHideTimer = setTimeout(()=>{ hideUI(); }, UI_HIDE_MS); }
  window.addEventListener('pointermove', ()=> resetUIHideTimer(), { passive:true });
  controls.addEventListener('pointerdown', ()=> showUI());

  // orientation helpers (keep menu horizontally locked -> remove roll)
  const zee = new THREE.Vector3(0,0,1);
  const qPortraitToThree = new THREE.Quaternion(-Math.sqrt(0.5),0,0,Math.sqrt(0.5));
  let deviceQuat = new THREE.Quaternion();
  let deviceOrientationEnabled = false;
  function getScreenOrientationDeg(){ if (screen && screen.orientation && typeof screen.orientation.angle === 'number') return screen.orientation.angle; return window.orientation || 0; }
  function setObjectQuaternionFromSensor(quatOut, alpha, beta, gamma){
    const orient = getScreenOrientationDeg();
    const deg = Math.PI/180;
    const e = new THREE.Euler((beta||0)*deg,(alpha||0)*deg,-(gamma||0)*deg,'YXZ');
    quatOut.setFromEuler(e);
    let baseRot = new THREE.Quaternion();
    if (orient === 90) baseRot.setFromAxisAngle(zee, -Math.PI/2);
    else if (orient === -90 || orient === 270) baseRot.setFromAxisAngle(zee, Math.PI/2);
    else if (orient === 180) baseRot.setFromAxisAngle(zee, Math.PI);
    quatOut.multiply(qPortraitToThree);
    quatOut.multiply(baseRot);
    // remove roll
    const ex = new THREE.Euler().setFromQuaternion(quatOut,'YXZ'); ex.z = 0; quatOut.setFromEuler(ex);
  }
  async function enableDeviceOrientation(){
    if (typeof DeviceOrientationEvent !== 'undefined' && typeof DeviceOrientationEvent.requestPermission === 'function'){
      try{
        const perm = await DeviceOrientationEvent.requestPermission();
        if (perm === 'granted') window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true);
        else window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true);
      }catch(e){ window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true); }
    } else {
      window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true);
    }
  }

  // ---- Camera selection and start ----
  async function chooseRearDeviceId(){
    try{
      const devs = await navigator.mediaDevices.enumerateDevices();
      const cams = devs.filter(d=>d.kind==='videoinput');
      for(const c of cams){
        const L=(c.label||'').toLowerCase();
        if (L.includes('back')||L.includes('rear')||L.includes('environment')||L.includes('main')||L.includes('wide')) return c.deviceId;
      }
      for(const c of cams){ const L=(c.label||'').toLowerCase(); if (!L.includes('front') && !L.includes('selfie')) return c.deviceId; }
      return cams.length ? cams[0].deviceId : null;
    }catch(e){ return null; }
  }

  async function startCameraStream(){
    const deviceId = await chooseRearDeviceId();
    const tryRes = [{w:3840,h:2160},{w:1920,h:1080},{w:1280,h:720}];
    const fpsCandidates = [60,30];
    for (const r of tryRes){
      for (const f of fpsCandidates){
        try{
          const constraints = deviceId
            ? { video:{ deviceId:{ exact: deviceId }, width:{ ideal: r.w }, height:{ ideal: r.h }, frameRate:{ ideal: f } }, audio:false }
            : { video:{ facingMode:{ ideal:'environment' }, width:{ ideal:r.w }, height:{ ideal:r.h }, frameRate:{ ideal:f } }, audio:false };
          const s = await navigator.mediaDevices.getUserMedia(constraints);
          return s;
        }catch(e){ /* try next */ }
      }
    }
    return navigator.mediaDevices.getUserMedia({ video:true, audio:false });
  }

  // ---- Renderer & Scenes (single-pass menu rendering to RT) ----
  let renderer, scene3D, perspectiveBase, rtMenu, orthoScene, orthoCamera, quadMesh;
  const FIXED_IPD = 0.064;
  let menuMesh = null, menuBar = null;
  const MENU_DISTANCE = 1.4;

  function initThreeOverlay(){
    const canvas = overlay;
    renderer = new THREE.WebGLRenderer({ canvas, antialias:true, alpha:true });
    renderer.setPixelRatio(window.devicePixelRatio || 1);
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.autoClear = false;

    // 3D scene (menu)
    scene3D = new THREE.Scene();
    scene3D.add(new THREE.AmbientLight(0xffffff,0.9));
    const dl = new THREE.DirectionalLight(0xffffff,0.25); dl.position.set(1,2,2); scene3D.add(dl);

    // perspective camera for menu render (single pass)
    perspectiveBase = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.01, 1000);
    perspectiveBase.position.set(0,0,0);

    // menu object (rounded-ish box look)
    const boxG = new THREE.BoxGeometry(0.9 * (1.5/1.0), 0.9, 0.02); // wide so looks like a screen
    const boxM = new THREE.MeshStandardMaterial({ color:0x0f6feb, roughness:0.45, metalness:0.05, transparent:true, opacity:0.96 });
    menuMesh = new THREE.Mesh(boxG, boxM);
    menuMesh.visible = false;
    scene3D.add(menuMesh);

    // pill bar at bottom of menu
    const barG = new THREE.BoxGeometry(0.4, 0.04, 0.002);
    const barM = new THREE.MeshStandardMaterial({ color:0xffffff, transparent:true, opacity:0.9 });
    menuBar = new THREE.Mesh(barG, barM);
    menuBar.position.set(0, - (0.9/2) - 0.03, 0.011);
    menuMesh.add(menuBar);

    // render target for single-pass menu rendering
    rtMenu = new THREE.WebGLRenderTarget(window.innerWidth, window.innerHeight, { minFilter:THREE.LinearFilter, magFilter:THREE.LinearFilter, format:THREE.RGBAFormat });

    // ortho scene used to draw the menu RT into each eye viewport
    orthoScene = new THREE.Scene();
    orthoCamera = new THREE.OrthographicCamera(-1,1,1,-1,0,1);
    const quadGeo = new THREE.PlaneGeometry(2,2);
    const quadMat = new THREE.MeshBasicMaterial({ map: rtMenu.texture });
    quadMesh = new THREE.Mesh(quadGeo, quadMat);
    orthoScene.add(quadMesh);

    // handle resize
    window.addEventListener('resize', ()=> {
      renderer.setSize(window.innerWidth, window.innerHeight);
      perspectiveBase.aspect = window.innerWidth / window.innerHeight; perspectiveBase.updateProjectionMatrix();
      rtMenu.setSize(window.innerWidth, window.innerHeight);
      layoutEyes(); updatePortrait();
    });

    // start render loop
    requestAnimationFrame(animate);
  }

  // helper: spawn menu in front (world-locked)
  function spawnMenu(){
    const forward = new THREE.Vector3(0,0,-1);
    // apply device orientation to forward if available
    if (deviceOrientationEnabled) forward.applyQuaternion(deviceQuat);
    const spawnPos = forward.clone().multiplyScalar(MENU_DISTANCE);
    menuMesh.position.copy(spawnPos);

    // face horizontally toward camera origin (keep horizontal (y) aligned)
    const toCam = new THREE.Vector3().subVectors(new THREE.Vector3(0,0,0), menuMesh.position);
    toCam.y = 0;
    menuMesh.lookAt(menuMesh.position.clone().add(toCam));
    menuMesh.up.set(0,1,0);

    // scale depending on FOV slider to keep perceived size stable
    const baseScale = Math.max(0.6, Math.min(2.0, (eyeScalePct/70)));
    menuMesh.scale.set(baseScale, baseScale, baseScale);
    menuMesh.visible = true;
    popScale(menuMesh, menuMesh.scale.x, 220);
  }
  function hideMenu(){ shrinkHide(menuMesh, 160); }

  function popScale(obj, target, dur=220){
    const start = performance.now(); const sx = obj.scale.x;
    (function step(now){
      const t = Math.min(1, (now - start)/dur);
      const e = 1 - Math.pow(1 - t, 3);
      const v = sx + (target - sx) * e; obj.scale.set(v,v,v);
      if(t < 1) requestAnimationFrame(step);
    })(performance.now());
  }
  function shrinkHide(obj, dur=160){
    const start = performance.now(); const sx = obj.scale.x;
    (function step(now){
      const t = Math.min(1, (now - start)/dur);
      const e = Math.pow(1 - t, 2);
      obj.scale.set(sx * e, sx * e, sx * e);
      if(t < 1) requestAnimationFrame(step);
      else { obj.visible = false; obj.scale.set(sx,sx,sx); }
    })(performance.now());
  }

  // ---- Hand tracking + pinch + smoothing ----
  let handsReady = false;
  let mpHands = null;
  let mpCamera = null;
  // smoothing - exponential moving average
  function EMA(alpha){ let val = null; return { push(x){ if(val==null) val = x.clone ? x.clone() : x; else if(x.clone) val.lerp(x, alpha); else val = val*(1-alpha)+x*alpha; return val; }, read(){ return val; } }; }

  // palm and pointer smoothing objects
  const palmPosEMA = EMA(0.35);
  const palmDirEMA = EMA(0.4);
  const pinchEMA = EMA(0.45);

  // pointer (3D) computed per-frame from palm and palm-forward
  let pointerWorld = new THREE.Vector3(); // smoothed pointer world position
  let isPinching = false;

  // attempt to initialize MediaPipe Hands
  async function initMediaPipeHands(){
    try{
      if (typeof window.Hands === 'undefined') {
        console.warn('MediaPipe Hands not available as window.Hands');
        return;
      }
      mpHands = new Hands({locateFile: (file) => {
        // default CDN location - rely on jsdelivr
        return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4/${file}`;
      }});
      mpHands.setOptions({
        maxNumHands: 1,
        modelComplexity: 1,
        minDetectionConfidence: 0.6,
        minTrackingConfidence: 0.6
      });
      mpHands.onResults(onMediaPipeResults);

      // we'll feed frames using a hidden offscreen video and Camera helper
      // but we already have the same stream on videoLeft/right; use videoLeft for feed
      mpCamera = new Camera(videoLeft, {
        onFrame: async ()=> { if (mpHands) await mpHands.send({image: videoLeft}); },
        width: 1280,
        height: 720
      });
      // don't start camera here: we start mpCamera.start() once stream exists
      handsReady = true;
      console.log('MediaPipe Hands initialized');
    }catch(e){
      console.error('initMediaPipeHands failed', e);
      handsReady = false;
    }
  }

  // handle MediaPipe detection results
  function onMediaPipeResults(results){
    if (!results.multiHandLandmarks || !results.multiHandedness || results.multiHandLandmarks.length===0) {
      // no hand
      pinchEMA.push(0);
      return;
    }
    const landmarks = results.multiHandLandmarks[0];
    // compute palm center as average of a subset (wrist + middle base)
    const wrist = landmarks[0];
    const middleBase = landmarks[9];
    const palm = { x:(wrist.x + middleBase.x)/2, y:(wrist.y + middleBase.y)/2, z:(wrist.z + middleBase.z)/2 };

    // palm 2D -> project to normalized device then to world later
    const pVec2 = new THREE.Vector3(palm.x, palm.y, palm.z);
    palmPosEMA.push(pVec2);

    // estimate palm-forward: using vector from wrist->middleFingerTip and cross product approximations
    // We produce a 3D direction in camera space approximated from landmark deltas:
    const indexTip = landmarks[8];
    const thumbTip = landmarks[4];
    // compute 2D direction from palm to camera-plane normal approx
    // Use vector wrist->middleBase as up direction, and wrist->indexTip as finger direction
    const v1 = new THREE.Vector3(middleBase.x - wrist.x, middleBase.y - wrist.y, middleBase.z - wrist.z).normalize();
    const v2 = new THREE.Vector3(indexTip.x - wrist.x, indexTip.y - wrist.y, indexTip.z - wrist.z).normalize();
    const palmNormal = new THREE.Vector3().crossVectors(v2, v1).normalize(); // approximate palm facing
    palmDirEMA.push(palmNormal);

    // pinch detection: distance between thumb tip and index tip (normalized)
    const dx = (thumbTip.x - indexTip.x);
    const dy = (thumbTip.y - indexTip.y);
    const dz = (thumbTip.z - indexTip.z);
    const dist = Math.sqrt(dx*dx + dy*dy + dz*dz);
    // threshold depends on hand size; use 0.05 typical, invert into strength
    const pinchStrength = Math.max(0, Math.min(1, (0.12 - dist) / 0.12)); // rough
    pinchEMA.push(pinchStrength);
  }

  // map palm-normal and palm-pos to world ray: convert normalized video coords -> screen coords -> ray through camera
  function computePointerWorld(){
    // read smoothed palm pos & dir from EMA
    const p = palmPosEMA.read();
    const d = palmDirEMA.read();
    const pinch = pinchEMA.read() || 0;
    isPinching = (pinch > 0.45);

    if (!p || !d) return false;

    // convert normalized mediaPipe coordinates (x: [0,1] left->right, y: [0,1] top->bottom)
    // to CSS pixel position on videoLeft (which fills eye windows)
    // We'll compute center of leftWin bounding box then transform
    // Choose the center of the left video for projection
    const leftRect = leftWin.getBoundingClientRect();
    const px = leftRect.left + leftRect.width * p.x;
    const py = leftRect.top + leftRect.height * p.y;

    // normalize to NDC for renderer: (x / W)*2 -1, (y / H)*-2 +1
    const ndc = new THREE.Vector2((px / window.innerWidth) * 2 - 1, - (py / window.innerHeight) * 2 + 1);

    // create ray from camera through ndc in world space
    const cam = perspectiveBase;
    const ray = new THREE.Raycaster();
    ray.setFromCamera(ndc, cam);

    // palm forward in camera space is approximately d but MediaPipe used video coords; we convert approximate:
    // We'll use the camera ray direction as base and offset by the palm normal rotated into world by camera orientation
    // compute target distance (default spawn distance)
    const dist = MENU_DISTANCE;
    // world point along ray
    const worldPoint = ray.ray.at(dist, new THREE.Vector3());

    // compute a forward vector in world: rotate palm-normal (in camera space) by camera quaternion
    // approximate palmNormal camera-space -> world
    // palm-normal currently is in video-space; map it to camera-space by flipping y and z sign some—approximation:
    const palmCam = new THREE.Vector3(-d.x, -d.y, -d.z); // heuristic
    palmCam.applyQuaternion(cam.quaternion); // rotate to world
    palmCam.normalize();

    // compute pointerWorld = worldPoint + palmCam * smallOffset (so the dot is slightly in front)
    const pointer = worldPoint.clone().add(palmCam.clone().multiplyScalar(0.1));
    // smooth world pointer with EMA-like lerp
    pointerWorld.lerp(pointer, 0.45);

    return true;
  }

  // ---- pinch-to-drag menu logic ----
  let grabbing = false;
  let grabOffset = new THREE.Vector3(); // offset from pointer to menu position when start grabbing

  function updateGrabLogic(){
    if (!menuMesh || !menuMesh.visible) return;
    // compute pointerWorld and isPinching set in computePointerWorld
    const ok = computePointerWorld();
    if (!ok) {
      // no hand information
      if (!isPinching) grabbing = false;
      return;
    }
    // ray from camera through pointer: we will compute intersection dist to menu plane
    // pointerWorld approximates a point on the ray at MENU_DISTANCE.
    const camPos = new THREE.Vector3(0,0,0);
    const toPointer = pointerWorld.clone().sub(camPos).normalize();
    // compute intersection with plane of menu (menu normal)
    const menuNormal = new THREE.Vector3(0,0,1).applyQuaternion(menuMesh.quaternion);
    const denom = menuNormal.dot(toPointer);
    if (Math.abs(denom) < 1e-3) {
      // ray nearly parallel; skip
      if (!isPinching) grabbing=false;
      return;
    }
    const planePoint = menuMesh.position.clone();
    const t = menuNormal.dot(planePoint.clone().sub(camPos)) / denom;
    const intersectPoint = camPos.clone().add(toPointer.clone().multiplyScalar(t));

    // when pinch begins, set grabOffset so relative position stays
    if (isPinching && !grabbing){
      grabbing = true;
      grabOffset.copy(menuMesh.position.clone().sub(intersectPoint));
    } else if (!isPinching && grabbing){
      grabbing = false;
    }

    if (grabbing){
      // desired menu position is intersectPoint + grabOffset, but we lerp for smoothing
      const desired = intersectPoint.clone().add(grabOffset);
      menuMesh.position.lerp(desired, 0.5); // smoothing factor
      // keep menu facing horizontally
      const toCam = new THREE.Vector3().subVectors(new THREE.Vector3(0,0,0), menuMesh.position); toCam.y = 0;
      menuMesh.lookAt(menuMesh.position.clone().add(toCam));
      menuMesh.up.set(0,1,0);
    }
  }

  // ---- compute viewports / layout (bottom-anchored, grow upward) ----
  let eyeScalePct = parseFloat(fovSlider.value || 70);
  fovVal.textContent = Math.round(eyeScalePct) + '%';
  function layoutEyes(){
    const scale = Math.max(0.3, Math.min(1.0, eyeScalePct/100));
    let eyeH = Math.round(window.innerHeight * scale);
    let eyeW = Math.floor(eyeH * 1.5);
    let gap = Math.max(8, Math.round(eyeW * 0.06));
    if (eyeW * 2 + gap > window.innerWidth){
      const avail = window.innerWidth - gap;
      eyeW = Math.floor(avail / 2);
      eyeH = Math.floor(eyeW * 2/3);
    }
    document.documentElement.style.setProperty('--eye-w', eyeW + 'px');
    document.documentElement.style.setProperty('--eye-h', eyeH + 'px');
    document.documentElement.style.setProperty('--gap', gap + 'px');
  }

  function updatePortrait(){
    if (window.innerHeight > window.innerWidth){
      portraitOverlay.style.display = 'flex';
      controls.classList.add('hidden');
      fullscreenBtn.style.display = 'none';
    } else {
      portraitOverlay.style.display = 'none';
      // restore UI visibility
      if (!controls.classList.contains('hidden')) controls.style.display='flex';
      if (controls.style.display !== 'none') fullscreenBtn.style.display='block';
    }
  }

  // ---- Double tap toggle menu ----
  let lastTap = 0;
  window.addEventListener('pointerdown', (ev)=>{
    const now = Date.now();
    if (now - lastTap < 300){
      // double-tap -> toggle menu
      if (!menuMesh) return;
      if (!menuMesh.visible) spawnMenu(); else hideMenu();
    }
    lastTap = now;
    resetUIHideTimer();
  });

  // show UI on tapping top area
  window.addEventListener('pointerdown', (ev)=>{ if (ev.clientY <= 140) showUI(); });

  // fullscreen
  fullscreenBtn.addEventListener('click', ()=>{ if (!document.fullscreenElement) document.documentElement.requestFullscreen().catch(()=>{}); else document.exitFullscreen(); resetUIHideTimer(); });

  // FOV slider
  fovSlider.addEventListener('input', ()=>{ eyeScalePct = parseFloat(fovSlider.value); fovVal.textContent = Math.round(eyeScalePct) + '%'; layoutEyes(); if (menuMesh) menuMesh.scale.setScalar(Math.max(0.6, eyeScalePct/70)); resetUIHideTimer(); });

  // ---- Render loop: single-pass menu -> RT, draw RT into both eye windows, then draw pointer overlay ----
  function animate(){
    requestAnimationFrame(animate);
    if (!renderer) return;

    // update device rotation to camera
    if (deviceOrientationEnabled && perspectiveBase) perspectiveBase.quaternion.copy(deviceQuat);

    // update three: render scene3D into rtMenu
    if (menuMesh && menuMesh.visible){
      // render menu scene into render target (single pass)
      renderer.setRenderTarget(rtMenu);
      renderer.clear(true,true,true);
      renderer.render(scene3D, perspectiveBase);
      renderer.setRenderTarget(null);
    }

    // Now render the menu texture into each eye window on the overlay canvas by scissoring
    const leftRect = leftWin.getBoundingClientRect();
    const rightRect = rightWin.getBoundingClientRect();
    const leftViewportY = window.innerHeight - leftRect.top - leftRect.height;

    renderer.setScissorTest(true);

    // Left eye: draw the menu RT texture mapped to full canvas quad (we can render quad -> scissored region)
    renderer.setScissor(leftRect.left, leftViewportY, leftRect.width, leftRect.height);
    renderer.setViewport(leftRect.left, leftViewportY, leftRect.width, leftRect.height);
    renderer.clearDepth();
    // draw quad (which samples rtMenu texture)
    renderer.render(orthoScene, orthoCamera);

    // Right eye
    const rightViewportY = window.innerHeight - rightRect.top - rightRect.height;
    renderer.setScissor(rightRect.left, rightViewportY, rightRect.width, rightRect.height);
    renderer.setViewport(rightRect.left, rightViewportY, rightRect.width, rightRect.height);
    renderer.clearDepth();
    renderer.render(orthoScene, orthoCamera);

    renderer.setScissorTest(false);

    // update hand pointer + grabbing
    if (handsReady) {
      updateGrabLogic();
    }

    // draw pointer dot using WebGL overlay (we'll paint a small circle into overlay canvas 2D context)
    // Instead of using a separate 2D overlay, we can draw a small HTML element; keep simple: update a CSS dot.
    updatePointerDot();
  }

  // pointer DOM element (white dot) - will be positioned inside the respective eye window center if pointer projects within
  let dotEl = null;
  function ensureDot(){
    if (!dotEl){
      dotEl = document.createElement('div');
      dotEl.className = 'dot';
      dotEl.style.width = '12px'; dotEl.style.height = '12px';
      dotEl.style.boxShadow = '0 0 10px rgba(255,255,255,0.9)';
      dotEl.style.pointerEvents = 'none';
      dotEl.style.display = 'none';
      dotEl.style.zIndex = 50;
      document.body.appendChild(dotEl);
    }
  }
  ensureDot();

  function worldToScreen(pos){
    // pos: THREE.Vector3 in world space. Project with perspectiveBase (camera at origin)
    const p = pos.clone();
    p.project(perspectiveBase);
    const x = (p.x + 1) / 2 * window.innerWidth;
    const y = (-p.y + 1) / 2 * window.innerHeight;
    return {x,y,visible: p.z < 1};
  }

  function updatePointerDot(){
    if (!pointerWorld) { dotEl.style.display='none'; return; }
    const scr = worldToScreen(pointerWorld);
    if (!scr.visible){ dotEl.style.display='none'; return; }
    // check if screen point lies within either eye window bounding rect
    const leftRect = leftWin.getBoundingClientRect();
    const rightRect = rightWin.getBoundingClientRect();
    let insideLeft = (scr.x >= leftRect.left && scr.x <= leftRect.right && scr.y >= leftRect.top && scr.y <= leftRect.bottom);
    let insideRight = (scr.x >= rightRect.left && scr.x <= rightRect.right && scr.y >= rightRect.top && scr.y <= rightRect.bottom);
    if (!insideLeft && !insideRight){
      dotEl.style.display='none';
      return;
    }
    dotEl.style.display='block';
    dotEl.style.left = (scr.x - 6) + 'px';
    dotEl.style.top = (scr.y - 6) + 'px';
  }

  // ---- MediaPipe init attempt ----
  await initMediaPipeHands();

  // ---- Start button flow ----
  startBtn.addEventListener('click', async ()=>{
    startBtn.style.display='none';
    await enableDeviceOrientation();
    showUI();
    try{
      const stream = await startCameraStream();
      // attach same stream to both video elements
      videoLeft.srcObject = stream;
      videoRight.srcObject = stream;
      // hide native controls / make extremely small offscreen for mpCamera to use (it uses videoLeft)
      videoLeft.style.objectFit = 'cover';
      videoRight.style.objectFit = 'cover';
      try { await videoLeft.play(); } catch(e){ console.warn('videoLeft play blocked', e); }
      try { await videoRight.play(); } catch(e){ console.warn('videoRight play blocked', e); }

      // start MediaPipe camera helper if available
      if (mpCamera) {
        try{ await mpCamera.start(); handsReady = true; } catch(e){ console.warn('mpCamera.start failed', e); handsReady=false; }
      }

      // init three overlay
      initThreeOverlay();

      // show overlay controls
      controls.style.display='flex';
      fullscreenBtn.style.display='block';
      layoutEyes();
      updatePortrait();
    }catch(err){
      console.error('camera start error', err);
      alert('Camera start failed: ' + (err && err.message ? err.message : err));
      startBtn.style.display='block';
    }
  });

  // ---- utility for debugging toggles ----
  window.addEventListener('resize', ()=> { layoutEyes(); updatePortrait(); });

  // initial layout
  layoutEyes();
  updatePortrait();

  // small helper to display status log briefly
  function flashLog(msg, ms=2200){
    logEl.textContent = msg;
    logEl.style.display = 'block';
    setTimeout(()=> logEl.style.display='none', ms);
  }

  // notify user if mediapipe not inited
  setTimeout(()=> {
    if (!handsReady) flashLog('Hand tracking not ready — using pinch when available',3000);
  }, 2000);

})();
</script>
</body>
</html>
