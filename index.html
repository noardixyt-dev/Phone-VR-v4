<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1.0,viewport-fit=cover" />
<title>Stereo Passthrough — All features (single-file)</title>
<style>
  :root{--outline:rgba(255,255,255,0.06)}
  html,body{height:100%;width:100%;margin:0;background:#000;color:#fff;font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial;overflow:hidden}
  /* eye windows container — centered vertically */
  #stereoWrap{position:fixed;inset:0;display:flex;justify-content:center;align-items:center;gap:var(--gap,12px);pointer-events:none;z-index:10}
  .eyeWin{width:var(--eye-w,360px);height:var(--eye-h,240px);border-radius:14px;overflow:hidden;border:2px solid var(--outline);box-shadow:0 10px 30px rgba(0,0,0,0.6);background:#000;position:relative;display:flex;align-items:center;justify-content:center}
  .eyeVideo{position:absolute;inset:0;width:100%;height:100%;object-fit:cover;transform-origin:center center;filter:none}
  /* overlay canvas (three.js) */
  canvas#overlay{position:fixed;left:0;top:0;width:100%;height:100%;z-index:40;pointer-events:none;display:block}
  /* UI */
  #controls{position:fixed;left:12px;top:10px;z-index:60;display:flex;gap:10px;align-items:center;pointer-events:auto;transition:opacity .28s,transform .28s}
  #controls.hidden{opacity:0;pointer-events:none;transform:translateY(-8px)}
  .control{background:rgba(0,0,0,0.45);backdrop-filter:blur(6px);padding:8px;border-radius:8px;font-size:13px;color:#fff}
  #fovSlider{width:220px}
  #fullscreenBtn{position:fixed;top:10px;right:10px;z-index:60;padding:8px 12px;border-radius:8px;background:rgba(255,255,255,0.06);border:1px solid rgba(255,255,255,0.06);color:#fff;font-size:14px;pointer-events:auto}
  #startBtn{position:fixed;left:50%;top:50%;transform:translate(-50%,-50%);z-index:80;padding:14px 18px;border-radius:10px;background:#111;color:#fff;border:1px solid rgba(255,255,255,0.06);cursor:pointer}
  #hint{position:fixed;left:50%;bottom:10px;transform:translateX(-50%);font-size:12px;background:rgba(0,0,0,0.35);padding:6px 10px;border-radius:8px;z-index:60}
  #portraitOverlay{position:fixed;inset:0;display:none;align-items:center;justify-content:center;background:rgba(0,0,0,0.92);z-index:9999;color:#fff;font-size:20px;padding:20px;text-align:center;pointer-events:auto}
  /* small debug (hidden by default) */
  #debugLog{position:fixed;left:10px;bottom:10px;color:#0f0;background:rgba(0,0,0,0.6);padding:6px;border-radius:6px;font-size:11px;z-index:9998;display:none}
</style>
</head>
<body>
  <button id="startBtn">Start VR (camera & motion)</button>

  <div id="controls" class="hidden" style="display:none">
    <div class="control">
      <div style="font-size:12px;margin-bottom:6px">FOV <span id="fovVal">70%</span></div>
      <input id="fovSlider" type="range" min="40" max="100" value="70" />
    </div>
  </div>

  <button id="fullscreenBtn" style="display:none">Fullscreen</button>
  <div id="hint">Double-tap to toggle menu • Tap top to show UI</div>
  <div id="portraitOverlay">Please rotate your device to landscape</div>
  <div id="debugLog"></div>

  <div id="stereoWrap" aria-hidden="true">
    <div id="leftWin" class="eyeWin">
      <video id="videoLeft" class="eyeVideo" playsinline autoplay muted></video>
    </div>
    <div id="rightWin" class="eyeWin">
      <video id="videoRight" class="eyeVideo" playsinline autoplay muted></video>
    </div>
  </div>

  <canvas id="overlay"></canvas>

  <!-- Three + MediaPipe (CDNs) -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>

<script>
/*
  Single-file app:
  - Rear camera → both eye <video> (object-fit:cover => 16:9 crop into eye 16:9->1.5:1 windows)
  - Overlay canvas renders a single 3D menu to an offscreen RT (single pass) and then blits that texture into each eye viewport
  - MediaPipe hands: palm dot rendered and used for pinch-to-drag
  - Double-tap toggles world-locked menu (3DOF). If WebXR available, code attempts WebXR 6DOF (fallback to deviceorientation)
  - UI top (FOV & fullscreen) auto-hide after 10s, tap top reveals
  - Eye windows scale/centering logic included
*/

/* ---------- DOM & state ---------- */
const startBtn = document.getElementById('startBtn');
const controls = document.getElementById('controls');
const fullscreenBtn = document.getElementById('fullscreenBtn');
const fovSlider = document.getElementById('fovSlider');
const fovVal = document.getElementById('fovVal');
const portraitOverlay = document.getElementById('portraitOverlay');
const debugLog = document.getElementById('debugLog');
const leftWin = document.getElementById('leftWin');
const rightWin = document.getElementById('rightWin');
const videoLeft = document.getElementById('videoLeft');
const videoRight = document.getElementById('videoRight');
const overlay = document.getElementById('overlay');

let stream = null;
let eyeScalePct = parseFloat(fovSlider.value);
fovVal.textContent = Math.round(eyeScalePct) + '%';
let uiHideTimer = null;
const UI_HIDE_MS = 10000;
function showUI(){ controls.style.display='flex'; controls.classList.remove('hidden'); fullscreenBtn.style.display='block'; resetUIHideTimer(); }
function hideUI(){ controls.classList.add('hidden'); fullscreenBtn.style.display='none'; }
function resetUIHideTimer(){ if(uiHideTimer) clearTimeout(uiHideTimer); uiHideTimer = setTimeout(()=>{ hideUI(); }, UI_HIDE_MS); }
window.addEventListener('pointermove', ()=> resetUIHideTimer(), { passive:true });
controls.addEventListener('pointerdown', ()=> showUI());

/* ---------- device orientation (landscape-calibrated, remove roll) ---------- */
const zee = new THREE.Vector3(0,0,1);
const qPortraitToThree = new THREE.Quaternion(-Math.sqrt(0.5),0,0,Math.sqrt(0.5));
let deviceQuat = new THREE.Quaternion();
let deviceOrientationEnabled = false;
function getScreenOrientationDeg(){ if (screen && screen.orientation && typeof screen.orientation.angle === 'number') return screen.orientation.angle; return window.orientation || 0; }
function setObjectQuaternionFromSensor(quatOut, alpha, beta, gamma){
  const orient = getScreenOrientationDeg(); const deg=Math.PI/180;
  const e = new THREE.Euler((beta||0)*deg, (alpha||0)*deg, -(gamma||0)*deg, 'YXZ');
  quatOut.setFromEuler(e);
  let baseRot = new THREE.Quaternion();
  if (orient===90) baseRot.setFromAxisAngle(zee,-Math.PI/2);
  else if (orient===-90||orient===270) baseRot.setFromAxisAngle(zee,Math.PI/2);
  else if (orient===180) baseRot.setFromAxisAngle(zee,Math.PI);
  quatOut.multiply(qPortraitToThree);
  quatOut.multiply(baseRot);
  const ex = new THREE.Euler().setFromQuaternion(quatOut,'YXZ'); ex.z = 0; quatOut.setFromEuler(ex);
}
async function enableDeviceOrientation(){
  if (typeof DeviceOrientationEvent !== 'undefined' && typeof DeviceOrientationEvent.requestPermission === 'function'){
    try{
      const perm = await DeviceOrientationEvent.requestPermission();
      if (perm==='granted') window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true);
      else window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true);
    }catch(e){ window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true); }
  } else {
    window.addEventListener('deviceorientation', ev=>{ deviceOrientationEnabled=true; setObjectQuaternionFromSensor(deviceQuat, ev.alpha, ev.beta, ev.gamma); }, true);
  }
}

/* ---------- camera selection / start (rear camera, resolution/fps fallback) ---------- */
async function enumerateVideoInputs(){ try{ const devs = await navigator.mediaDevices.enumerateDevices(); return devs.filter(d=>d.kind==='videoinput'); }catch(e){ return []; } }
async function chooseRearDeviceId(){
  const cams = await enumerateVideoInputs();
  for(const c of cams){ const L=(c.label||'').toLowerCase(); if(L.includes('back')||L.includes('rear')||L.includes('environment')||L.includes('main')||L.includes('wide')) return c.deviceId; }
  for(const c of cams){ const L=(c.label||'').toLowerCase(); if(!L.includes('front') && !L.includes('selfie')) return c.deviceId; }
  return cams.length?cams[0].deviceId:null;
}
async function startCameraStream(){
  const deviceId = await chooseRearDeviceId();
  const res = [{w:3840,h:2160},{w:1920,h:1080},{w:1280,h:720}];
  const fpsCandidates = [60,30];
  for(const r of res){
    for(const fps of fpsCandidates){
      try {
        const constraints = deviceId
          ? { video:{ deviceId:{ exact: deviceId }, width:{ ideal: r.w }, height:{ ideal: r.h }, frameRate:{ ideal: fps } }, audio:false }
          : { video:{ facingMode:{ ideal:'environment' }, width:{ ideal: r.w }, height:{ ideal: r.h }, frameRate:{ ideal: fps } }, audio:false };
        const s = await navigator.mediaDevices.getUserMedia(constraints);
        return s;
      } catch(e){ /* try next */ }
    }
  }
  return navigator.mediaDevices.getUserMedia({ video:true, audio:false });
}

/* ---------- layout eyes (center vertically, scale from bottom->middle behavior) ---------- */
function layoutEyes(){
  const scale = Math.max(0.3, Math.min(1.0, eyeScalePct/100));
  let eyeH = Math.round(window.innerHeight * scale);
  let eyeW = Math.floor(eyeH * 1.5); // 1.5:1 target window ratio
  let gap = Math.max(8, Math.round(eyeW * 0.06));
  if (eyeW * 2 + gap > window.innerWidth){
    const avail = window.innerWidth - gap;
    eyeW = Math.floor(avail / 2);
    eyeH = Math.floor(eyeW / 1.5);
  }
  // center vertically (user wanted windows move into middle when smaller)
  const offsetY = Math.floor((window.innerHeight - eyeH)/2);
  leftWin.style.marginTop = offsetY + 'px';
  rightWin.style.marginTop = offsetY + 'px';
  document.documentElement.style.setProperty('--eye-w', eyeW + 'px');
  document.documentElement.style.setProperty('--eye-h', eyeH + 'px');
  document.documentElement.style.setProperty('--gap', gap + 'px');
}

/* ---------- Three overlay & single-pass menu rendering ---------- */
let renderer, scene3D, perspectiveBase, camLeft, camRight, rtMenu, postScene, postMat, postCamera;
let menu3D = null;
const FIXED_IPD = 0.064;
function initThree(){
  renderer = new THREE.WebGLRenderer({ canvas: overlay, antialias: true, alpha: true });
  renderer.setPixelRatio(Math.min(2, window.devicePixelRatio || 1));
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.autoClear = false;

  // 3D scene for menu (world-space)
  scene3D = new THREE.Scene();
  scene3D.add(new THREE.AmbientLight(0xffffff, 0.8));
  const dl = new THREE.DirectionalLight(0xffffff, 0.25); dl.position.set(1,2,2); scene3D.add(dl);

  perspectiveBase = new THREE.PerspectiveCamera(70, window.innerWidth/window.innerHeight, 0.01, 1000);
  camLeft = perspectiveBase.clone();
  camRight = perspectiveBase.clone();

  // menu 3D: 16:9 plane + pill bar
  const menuW = 1.4;
  const menuH = menuW * 9/16;
  const geo = new THREE.PlaneGeometry(menuW, menuH);
  const mat = new THREE.MeshStandardMaterial({ color:0x1f6feb, roughness:0.6, metalness:0.05, emissive:0x001428 });
  menu3D = new THREE.Mesh(geo, mat);
  menu3D.visible = false;
  scene3D.add(menu3D);

  const barG = new THREE.BoxGeometry(menuW*0.5, menuH*0.08, 0.01);
  const barM = new THREE.MeshStandardMaterial({ color:0xffffff, transparent:true, opacity:0.9, emissive:0x000000 });
  const bar = new THREE.Mesh(barG, barM);
  bar.position.set(0, -menuH/2 - (menuH*0.08)/2 - 0.02, 0.01);
  menu3D.add(bar);
  menu3D.userData.dragBar = bar;

  // render target (menu rendered once)
  rtMenu = new THREE.WebGLRenderTarget(1024, 576, { minFilter:THREE.LinearFilter, magFilter:THREE.LinearFilter, format:THREE.RGBAFormat });
  // post scene: render the rtMenu.texture to quads (we'll use this to blit into each eye viewport)
  postScene = new THREE.Scene();
  postCamera = new THREE.OrthographicCamera(-1,1,1,-1,0,1);
  const fs = new THREE.PlaneGeometry(2,2);
  postMat = new THREE.MeshBasicMaterial({ map: rtMenu.texture });
  const postQuad = new THREE.Mesh(fs, postMat);
  postScene.add(postQuad);

  window.addEventListener('resize', ()=> {
    if(renderer) renderer.setSize(window.innerWidth, window.innerHeight);
    if(perspectiveBase){ perspectiveBase.aspect = window.innerWidth/window.innerHeight; perspectiveBase.updateProjectionMatrix(); }
    layoutEyes();
  });
}

/* Render flow:
   - Render scene3D to rtMenu (single pass)
   - For each eye: set scissor/viewport to eye window rect, render the menu quad (postScene) there (no extra 3D computations).
   - Also leave video <video> elements visible underneath (they are DOM elements)
*/
function renderFrame(){
  requestAnimationFrame(renderFrame);
  if(!renderer) return;

  // orientation
  if(deviceOrientationEnabled) perspectiveBase.quaternion.copy(deviceQuat);
  else perspectiveBase.quaternion.identity();

  // smooth menu facing horizontally each frame (but keep world-anchored)
  if(menu3D && menu3D.visible){
    // face horizontally towards the camera origin (0,0,0)
    const toCam = new THREE.Vector3().subVectors(new THREE.Vector3(0,0,0), menu3D.position);
    toCam.y = 0; // keep horizontal only
    const target = menu3D.position.clone().add(toCam);
    menu3D.lookAt(target);
    menu3D.up.set(0,1,0);
  }

  // render menu scene to RT once
  renderer.setRenderTarget(rtMenu);
  renderer.clear(true,true,true);
  // use a temporary camera that looks at origin with same orientation as perspectiveBase (we want the menu to be rendered from camera's POV)
  const tmpCam = perspectiveBase.clone();
  tmpCam.position.set(0,0,0);
  tmpCam.quaternion.copy(perspectiveBase.quaternion);
  tmpCam.updateMatrixWorld();
  renderer.render(scene3D, tmpCam);
  renderer.setRenderTarget(null);

  // compute eye rects (use DOM bounding boxes)
  const leftRect = leftWin.getBoundingClientRect();
  const rightRect = rightWin.getBoundingClientRect();
  const canvasH = overlay.height = window.innerHeight;
  const canvasW = overlay.width = window.innerWidth;

  renderer.setScissorTest(true);

  // left eye: draw quad with rtMenu texture to that viewport
  const leftViewportY = canvasH - leftRect.top - leftRect.height;
  renderer.setScissor(Math.round(leftRect.left), Math.round(leftViewportY), Math.round(leftRect.width), Math.round(leftRect.height));
  renderer.setViewport(Math.round(leftRect.left), Math.round(leftViewportY), Math.round(leftRect.width), Math.round(leftRect.height));
  // optionally tint / add vignette if desired; for now draw the menu quad
  postMat.map = rtMenu.texture;
  renderer.clearDepth();
  renderer.render(postScene, postCamera);

  // right eye
  const rightViewportY = canvasH - rightRect.top - rightRect.height;
  renderer.setScissor(Math.round(rightRect.left), Math.round(rightViewportY), Math.round(rightRect.width), Math.round(rightRect.height));
  renderer.setViewport(Math.round(rightRect.left), Math.round(rightViewportY), Math.round(rightRect.width), Math.round(rightRect.height));
  renderer.clearDepth();
  renderer.render(postScene, postCamera);

  renderer.setScissorTest(false);
}

/* ---------- Menu spawn / world-lock / pop animation ---------- */
const MENU_DISTANCE = 1.2;
function spawnMenuAtForward(){
  const forward = new THREE.Vector3(0,0,-1);
  forward.applyQuaternion(deviceOrientationEnabled ? deviceQuat : new THREE.Quaternion());
  const pos = forward.multiplyScalar(MENU_DISTANCE);
  menu3D.position.copy(pos);
  // horizontal facing: do not pitch
  const toCam = new THREE.Vector3().subVectors(new THREE.Vector3(0,0,0), menu3D.position);
  toCam.y = 0;
  menu3D.lookAt(menu3D.position.clone().add(toCam));
  menu3D.up.set(0,1,0);
  menu3D.scale.setScalar(eyeScalePct/70);
  menu3D.visible = true;
  // tiny pop
  popScale(menu3D, menu3D.scale.x * 1.0, 240);
}
function hideMenu(){ shrinkHide(menu3D, 160); }

function popScale(obj, target, dur){
  const start = performance.now();
  const sx = obj.scale.x;
  function step(now){
    const t = Math.min(1, (now-start)/dur);
    const e = 1 - Math.pow(1-t,3);
    const v = sx + (target - sx) * e;
    obj.scale.setScalar(v);
    if(t<1) requestAnimationFrame(step);
  }
  requestAnimationFrame(step);
}
function shrinkHide(obj, dur){
  const start = performance.now();
  const sx = obj.scale.x;
  function step(now){
    const t = Math.min(1,(now-start)/dur);
    const e = Math.pow(1-t,2);
    obj.scale.setScalar(sx*e);
    if(t<1) requestAnimationFrame(step); else { obj.visible=false; obj.scale.setScalar(sx); }
  }
  requestAnimationFrame(step);
}

/* ---------- MediaPipe Hands integration (palm dot + pinch-to-drag) ---------- */
/* We'll feed the same rear camera video element (videoLeft) into the MediaPipe model (it accepts images).
   We'll implement a requestVideoFrameCallback loop to send frames and draw palm dot on overlay (2D)
   For drag: detect pinch (distance between thumb tip (4) and index tip (8)). When pinch starts, record palm world depth (menu distance),
   and move menu3D position by mapping normalized palm screen coords to world space at that distance.
*/
let hands; // MediaPipe Hands instance
let mpActive = false;
let pinchActive = false;
let pinchStart = null;
let lastPalmWorld = null;
const PALM_SMOOTH = 0.12;

function initMediaPipeHands(){
  hands = new Hands({locateFile: (f)=>`https://cdn.jsdelivr.net/npm/@mediapipe/hands/${f}`});
  hands.setOptions({maxNumHands:1,modelComplexity:1,minDetectionConfidence:0.7,minTrackingConfidence:0.6});
  hands.onResults(onHandsResults);
  mpActive = true;
  // Use requestVideoFrameCallback if available
  const loopFrame = ()=>{
    if(!videoLeft || videoLeft.readyState < 2){ requestAnimationFrame(loopFrame); return; }
    try { hands.send({image: videoLeft}); } catch(e){}
    if(typeof videoLeft.requestVideoFrameCallback === 'function'){
      videoLeft.requestVideoFrameCallback(()=> requestAnimationFrame(loopFrame));
    } else {
      setTimeout(()=> requestAnimationFrame(loopFrame), 1000/30);
    }
  };
  requestAnimationFrame(loopFrame);
}

// canvas 2D overlay for palm dot & debug; note: overlay canvas is also used by three renderer,
// we will draw the palm dot directly using the canvas 2D context after three renders by accessing its context.
function onHandsResults(results){
  // We'll draw palm dot on an extra 2D canvas overlaid; simpler: draw directly on overlay's 2D context after clearing via three render.
  // To avoid interfering with three's WebGL canvas, create a small transparent 2D overlay canvas on top.
  drawPalmDot(results);
  handlePinchDrag(results);
}

/* create 2D overlay canvas (top layer) */
const dotCanvas = document.createElement('canvas');
dotCanvas.style.position='fixed';
dotCanvas.style.left='0';
dotCanvas.style.top='0';
dotCanvas.style.pointerEvents='none';
dotCanvas.style.zIndex='60';
dotCanvas.width = window.innerWidth;
dotCanvas.height = window.innerHeight;
document.body.appendChild(dotCanvas);
const dotCtx = dotCanvas.getContext('2d');

window.addEventListener('resize', ()=>{ dotCanvas.width = window.innerWidth; dotCanvas.height = window.innerHeight; });

function drawPalmDot(results){
  dotCtx.clearRect(0,0,dotCanvas.width,dotCanvas.height);
  if(results.multiHandLandmarks && results.multiHandLandmarks.length>0){
    const lm = results.multiHandLandmarks[0];
    // palm center approx: use landmark 0 (wrist) or average 0+1+2 maybe; we'll use landmark 0 (wrist) & 9 (palm center)
    const p = lm[0]; // normalized
    const x = p.x * dotCanvas.width;
    const y = p.y * dotCanvas.height;
    // ensure inside eye windows: only show if palm projects within combined eye rects
    const leftRect = leftWin.getBoundingClientRect();
    const rightRect = rightWin.getBoundingClientRect();
    const inLeft = (x >= leftRect.left && x <= leftRect.right && y >= leftRect.top && y <= leftRect.bottom);
    const inRight = (x >= rightRect.left && x <= rightRect.right && y >= rightRect.top && y <= rightRect.bottom);
    if(!(inLeft || inRight)) return; // don't draw if outside both eyes
    dotCtx.save();
    dotCtx.beginPath();
    dotCtx.fillStyle = 'rgba(255,255,255,1)';
    dotCtx.shadowColor = 'rgba(255,255,255,0.9)';
    dotCtx.shadowBlur = 14;
    dotCtx.arc(x, y, 8, 0, Math.PI*2);
    dotCtx.fill();
    dotCtx.restore();
  }
}

/* Pinch detection + drag */
function handlePinchDrag(results){
  if(!menu3D) return;
  if(results.multiHandLandmarks && results.multiHandLandmarks.length>0){
    const lm = results.multiHandLandmarks[0];
    const thumb = lm[4];
    const index = lm[8];
    const palm = lm[0];
    const dx = (thumb.x - index.x);
    const dy = (thumb.y - index.y);
    const dist = Math.sqrt(dx*dx + dy*dy);
    // threshold: tuned empirically
    const pinchThreshold = 0.04;
    if(dist < pinchThreshold){
      // pinch active
      if(!pinchActive){
        pinchActive = true;
        pinchStart = { palm: palm, menuPosStart: menu3D.position.clone() };
      }
      // map palm normalized coords to world at current menu distance
      const ndcX = (palm.x * 2) - 1;
      const ndcY = -((palm.y * 2) - 1);
      // compute a point on camera near plane at menu distance
      const cam = perspectiveBase;
      const distance = menu3D.position.length() || MENU_DISTANCE;
      const vFov = cam.fov * Math.PI/180;
      const worldH = 2 * Math.tan(vFov/2) * distance;
      const worldW = worldH * cam.aspect;
      const worldX = ndcX * worldW/2;
      const worldY = ndcY * worldH/2;
      const worldPoint = new THREE.Vector3(worldX, worldY, -distance);
      // transform by camera quaternion
      worldPoint.applyQuaternion(cam.quaternion);
      // desired position = cameraOrigin (0,0,0) + worldPoint
      const desired = worldPoint.clone();
      // smooth lerp
      menu3D.position.lerp(desired, PALM_SMOOTH);
    } else {
      pinchActive = false;
      pinchStart = null;
    }
  } else {
    pinchActive = false;
    pinchStart = null;
  }
}

/* ---------- Input handling: double-tap toggles menu, top tap reveals UI ---------- */
let lastTap = 0;
window.addEventListener('pointerdown', (e)=>{
  // double-tap detection
  const now = Date.now();
  if(now - lastTap < 300){
    if(!menu3D.visible) spawnMenuAtForward(); else hideMenu();
  }
  lastTap = now;
  // top tap reveals UI
  if(e.clientY <= 140) showUI();
});

/* ---------- start flow ---------- */
startBtn.addEventListener('click', async ()=>{
  startBtn.style.display='none';
  await enableDeviceOrientation();
  try {
    stream = await startCameraStream();
    // attach stream to both video elements (same stream)
    videoLeft.srcObject = stream;
    videoRight.srcObject = stream;
    // play videos (user gesture satisfied)
    try{ await videoLeft.play(); } catch(e){ console.warn('left play blocked', e); }
    try{ await videoRight.play(); } catch(e){ console.warn('right play blocked', e); }
    // layout/ui
    controls.style.display='flex';
    fullscreenBtn.style.display='block';
    layoutEyes();
    updatePortrait();
    // three + menu
    initThree();
    // init mediapipe
    initMediaPipeHands();
    // start rendering loop
    renderFrame();
    // start dot rendering loop (MediaPipe will call onHandsResults)
  } catch(err){
    console.error('camera start failed', err);
    alert('Camera access failed: ' + (err && err.message ? err.message : err));
    startBtn.style.display='block';
  }
});

/* ---------- portrait overlay handling ---------- */
function updatePortrait(){
  portraitOverlay.style.display = (window.innerHeight > window.innerWidth) ? 'flex' : 'none';
  if (portraitOverlay.style.display === 'flex') { hideUI(); }
}
window.addEventListener('resize', ()=>{ layoutEyes(); updatePortrait(); if(renderer) renderer.setSize(window.innerWidth, window.innerHeight); if(perspectiveBase){ perspectiveBase.aspect = window.innerWidth/window.innerHeight; perspectiveBase.updateProjectionMatrix(); } dotCanvas.width = window.innerWidth; dotCanvas.height = window.innerHeight; });

/* ---------- helper: attempt to use WebXR for better 6DOF when available (non-blocking) ---------- */
async function tryEnableWebXR(){
  if(navigator.xr && navigator.xr.isSessionSupported){
    try{
      const supported = await navigator.xr.isSessionSupported('immersive-ar');
      if(supported){
        // We won't start a session automatically (user needs to accept), but if desired we could provide a button.
        console.log('WebXR immersive-ar supported (will not auto-start)');
      }
    }catch(e){}
  }
}
tryEnableWebXR();

/* ---------- simple utility pop/shrink for menu (reuse from above) ---------- */
function spawnMenuAtForward(){
  if(!menu3D) return;
  const forward = new THREE.Vector3(0,0,-1);
  if(deviceOrientationEnabled) forward.applyQuaternion(deviceQuat);
  const pos = forward.multiplyScalar(MENU_DISTANCE);
  menu3D.position.copy(pos);
  const toCam = new THREE.Vector3().subVectors(new THREE.Vector3(0,0,0), menu3D.position);
  toCam.y = 0;
  menu3D.lookAt(menu3D.position.clone().add(toCam));
  menu3D.up.set(0,1,0);
  menu3D.scale.setScalar(eyeScalePct/70);
  menu3D.visible = true;
  popScale(menu3D, menu3D.scale.x, 220);
}

/* ---------- small helpers ---------- */
function popScale(obj, target, dur){
  const start = performance.now(); const sx = obj.scale.x;
  function step(now){
    const t = Math.min(1,(now-start)/dur); const e = 1 - Math.pow(1-t,3);
    const v = sx + (target - sx) * e; obj.scale.setScalar(v);
    if(t<1) requestAnimationFrame(step);
  }
  requestAnimationFrame(step);
}
function shrinkHide(obj, dur){
  if(!obj) return;
  const start = performance.now(); const sx = obj.scale.x;
  function step(now){
    const t = Math.min(1,(now-start)/dur); const e = Math.pow(1-t,2);
    obj.scale.setScalar(sx*e);
    if(t<1) requestAnimationFrame(step); else { obj.visible=false; obj.scale.setScalar(sx); }
  }
  requestAnimationFrame(step);
}

/* ---------- init MediaPipe Hands object (deferred) ---------- */
function Hands(config){ return new window.Hands(config); } // wrapper to be explicit

/* ---------- dot canvas init (overlay used by three.js WebGL so we use separate 2D canvas) ---------- */
const dotCanvas = document.createElement('canvas');
dotCanvas.style.position='fixed'; dotCanvas.style.left='0'; dotCanvas.style.top='0'; dotCanvas.style.pointerEvents='none';
dotCanvas.style.zIndex='61'; dotCanvas.width = window.innerWidth; dotCanvas.height = window.innerHeight;
document.body.appendChild(dotCanvas);
const dotCtx = dotCanvas.getContext('2d');

/* ensure MediaPipe is loaded then create instance */
function initMediaPipeHands(){
  if(typeof Hands === 'undefined' || !window.Hands){
    console.warn('MediaPipe Hands is not available');
    return;
  }
  hands = new Hands({locateFile: (file)=>`https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
  hands.setOptions({maxNumHands:1,modelComplexity:1,minDetectionConfidence:0.6,minTrackingConfidence:0.6});
  hands.onResults((results)=>{ 
    // draw palm dot
    dotCtx.clearRect(0,0,dotCanvas.width,dotCanvas.height);
    if(results.multiHandLandmarks && results.multiHandLandmarks.length>0){
      const lm = results.multiHandLandmarks[0];
      const palm = lm[0];
      const x = palm.x * dotCanvas.width;
      const y = palm.y * dotCanvas.height;
      // check in-eye bounds
      const leftRect = leftWin.getBoundingClientRect();
      const rightRect = rightWin.getBoundingClientRect();
      const inLeft = (x>=leftRect.left && x<=leftRect.right && y>=leftRect.top && y<=leftRect.bottom);
      const inRight = (x>=rightRect.left && x<=rightRect.right && y>=rightRect.top && y<=rightRect.bottom);
      if(inLeft||inRight){
        dotCtx.save();
        dotCtx.beginPath();
        dotCtx.fillStyle = 'white';
        dotCtx.shadowColor = 'white';
        dotCtx.shadowBlur = 14;
        dotCtx.arc(x,y,9,0,Math.PI*2);
        dotCtx.fill();
        dotCtx.restore();
      }
    } else {
      dotCtx.clearRect(0,0,dotCanvas.width,dotCanvas.height);
    }
    // handle pinch-to-drag
    handlePinchDrag(results);
  });

  // use requestVideoFrameCallback or interval to feed frames from the rear video
  (function feed(){
    if(!videoLeft || videoLeft.readyState < 2){ requestAnimationFrame(feed); return; }
    try { hands.send({image: videoLeft}); } catch(e){ /* ignore */ }
    if(typeof videoLeft.requestVideoFrameCallback === 'function') videoLeft.requestVideoFrameCallback(()=> requestAnimationFrame(feed));
    else setTimeout(()=> requestAnimationFrame(feed), 1000/30);
  })();
}

/* ---------- ready: expose resize and run ---------- */
window.addEventListener('resize', ()=>{ dotCanvas.width = window.innerWidth; dotCanvas.height = window.innerHeight; });
updatePortrait();
layoutEyes();

</script>
</body>
</html>
